
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Starting spidy Web Crawler version 1.6.5
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Report any problems to GitHub at https://github.com/rivermont/spidy
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Creating classes...
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Creating functions...
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Creating variables...
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Successfully imported spidy Web Crawler version 1.6.5.
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Call `crawler.main()` to start crawling, or refer to DOCS.md to see use of specific functions.
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Should spidy load settings from an available config file? (y/n):
[00:47:48] [spidy] [WORKER #0] [INIT] [INFO]: Please enter the following arguments. Leave blank to use the default values.
[00:47:48] [spidy] [WORKER #0] [INIT] [INPUT]: How many parallel threads should be used for crawler? (Default: 1):